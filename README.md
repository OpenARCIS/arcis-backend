<p align="center">
  <h1 align="center">ARCIS</h1>
  <p align="center"><b>Autonomous Reasoning and Contextual Intelligence System</b></p>
  <p align="center">
    A multi-agent AI backend powered by LangGraph that autonomously manages emails, schedules, bookings, and conversations â€” with voice synthesis, long-term memory, and human-in-the-loop oversight.
  </p>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/python-3.11+-blue?style=flat-square" />
  <img src="https://img.shields.io/badge/framework-FastAPI-009688?style=flat-square" />
  <img src="https://img.shields.io/badge/orchestration-LangGraph-orange?style=flat-square" />
  <img src="https://img.shields.io/badge/database-MongoDB-47A248?style=flat-square" />
  <img src="https://img.shields.io/badge/memory-Qdrant-DC382D?style=flat-square" />
</p>

---

## Table of Contents

- [Overview](#overview)
- [Features](#features)
  - [To Do](#to-do)
- [Getting Started](#getting-started)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
  - [Docker Installation](#docker-installation)
  - [Environment Variables](#environment-variables)
  - [Google OAuth Setup](#google-oauth-setup)
  - [Pocket TTS Setup](#pocket-tts-setup)
  - [Running the Server](#running-the-server)
- [System Architecture](#system-architecture)
  - [High-Level Architecture](#high-level-architecture)
  - [Project Structure](#project-structure)
  - [Core Components](#core-components)
  - [Agent System](#agent-system)
  - [Memory System](#memory-system)
  - [LLM Provider System](#llm-provider-system)
- [Workflows](#workflows)
  - [Manual Workflow (Chat)](#manual-workflow-chat)
  - [Autonomous Workflow (Email Processing)](#autonomous-workflow-email-processing)
  - [Human-in-the-Loop (HITL)](#human-in-the-loop-hitl)
- [API Reference](#api-reference)
  - [Chat](#chat)
  - [Gmail Authentication](#gmail-authentication)
  - [Calendar](#calendar)
  - [Autonomous Flow](#autonomous-flow)
  - [Onboarding](#onboarding)
  - [Settings](#settings)

---

## Overview

**ARCIS** is an AI-powered personal assistant backend built on **FastAPI** and **LangGraph**. It uses a multi-agent architecture where specialized agents collaborate to handle complex tasks â€” from drafting emails and managing your calendar to searching the web and making bookings.



---

## Features

- ğŸ¤– **Multi-Agent Orchestration** â€” Planner â†’ Supervisor â†’ Specialized Agents â†’ Replanner loop
- ğŸ“§ **Gmail Integration** â€” Read, compose, and send emails via Google OAuth 2.0
- ğŸ“… **Calendar Management** â€” Events, todos, and reminders via built in Calendar
- ğŸ§  **Dual Memory System** â€” Short-term (LangGraph checkpoints) + Long-term (Qdrant semantic search)
- ğŸ—£ï¸ **Text-to-Speech** â€” Real-time voice synthesis via Pocket TTS with custom voice cloning
- ğŸ”„ **Human-in-the-Loop** â€” Agents can pause and ask for user input on sensitive actions
- ğŸ¯ **User Onboarding** â€” LLM-powered conversational interview that learns user preferences
- âš™ï¸ **Dynamic LLM Config** â€” Switch models/providers per agent at runtime via the settings API
- ğŸ”Œ **Multi-Provider LLM** â€” Supports Gemini, Groq, Cerebras, Mistral, OpenRouter or any OpenAI compatible API
- ğŸ“Š **Token Tracking** â€” Per-agent token usage monitoring

### To Do

- [ ] Add MCP agent
- [ ] Add specialized coding agent
- [ ] Refactor all codes
- [ ] Add Telegram as a message channel
- [ ] Add login page
- [ ] Add speech to text
- [ ] Add files to chat (also add VLM)
- [ ] Change system prompts to include agent skills
- [ ] Optimize checkpointing memory
- [ ] Add cron jobs

---

## Getting Started

### Prerequisites

| Dependency | Version | Purpose |
|------------|---------|---------|
| **Python** | 3.11+ | Runtime |
| **MongoDB** | 6.0+ | Primary database, checkpointer, chat history |
| **Qdrant** | 1.7+ | Vector database for long-term semantic memory |

### Installation

```bash
# Clone the repository
git clone https://github.com/OpenARCIS/arcis-backend.git
cd arcis-backend

# Create a virtual environment
python -m venv .venv

# Activate it
# Windows:
.venv\Scripts\activate
# Linux/macOS:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Docker Installation

You can also run ARCIS using Docker. A minimal Dockerfile is provided.

```bash
# Build the Docker image
docker build -t arcis-backend .

# Run the container (make sure to pass the .env file if needed)
docker run -p 8501:8501 --env-file .env arcis-backend
```

### Environment Variables

Create a `.env` file in the project root. The server loads it automatically in non-production environments.

#### Required

| Variable | Description | Example |
|----------|-------------|---------|
| `DATABASE_URL` | MongoDB connection string | `mongodb://user:pass@host:27017/` |
| `DATABASE_NAME` | MongoDB database name | `arcis_db` |

#### LLM API Keys

You need **at least one** LLM provider key. The system uses a factory pattern, so only the providers you configure for your agents need keys.

| Variable | Provider | Used For |
|----------|----------|----------|
| `GEMINI_API` | Google Gemini | LLM inference + online embeddings |
| `GROQ_API_KEY` | Groq | Fast inference (Llama, Qwen, etc.) |
| `CEREBRAS_API_KEY` | Cerebras | Llama inference |
| `MISTRAL_API_KEY` | Mistral AI | Mistral/Ministral models |
| `OPENROUTER_API_KEY` | OpenRouter | Access to 100+ models via unified API |

#### Google OAuth (Gmail & Calendar)

| Variable | Description | Default |
|----------|-------------|---------|
| `CLIENT_SECRETS_FILE` | Path to Google OAuth credentials JSON | `google_credentials.json` |
| `GOOGLE_REDIRECT_URI` | OAuth callback URL | `http://localhost:8000/` |
| `OAUTHLIB_INSECURE_TRANSPORT` | Allow HTTP for local testing (set `1`) | `1` |

#### Qdrant (Long-Term Memory)

| Variable | Description | Default |
|----------|-------------|---------|
| `QDRANT_URL` | Qdrant server URL | `http://localhost:6333` |
| `QDRANT_API_KEY` | Qdrant API key (if using Qdrant Cloud) | `None` |
| `EMBEDDING_MODE` | `offline` (FastEmbed/CPU) or `online` (Gemini API) | `offline` |

#### TTS (Pocket TTS)

| Variable | Description | Default |
|----------|-------------|---------|
| `TTS_DEFAULT_VOICE` | Default voice preset name for Pocket TTS | `alba` |

#### Example `.env`

```env
# Database
DATABASE_URL=mongodb://user:password@localhost:27017/
DATABASE_NAME=arcis_db

# LLM Providers (add keys for providers you use)
GEMINI_API=your_gemini_api_key
GROQ_API_KEY=your_groq_api_key
MISTRAL_API_KEY=your_mistral_api_key
CEREBRAS_API_KEY=your_cerebras_api_key
OPENROUTER_API_KEY=your_openrouter_api_key

# Google OAuth
GOOGLE_REDIRECT_URI=http://localhost:8000/gmail/auth/callback

# Qdrant
QDRANT_URL=http://localhost:6333
EMBEDDING_MODE=offline

# TTS (check Pocket TTS docs for more info on available voices)
TTS_DEFAULT_VOICE=alba
```

### Google OAuth Setup

ARCIS uses **Google OAuth 2.0** to access Gmail and Google Calendar on behalf of the user.

1. **Create a Google Cloud project** at [console.cloud.google.com](https://console.cloud.google.com/).
2. **Enable APIs**: Gmail API, Google Calendar API.
3. **Create OAuth 2.0 credentials** (Web application type).
4. **Add redirect URI**: Set it to match your `GOOGLE_REDIRECT_URI` env var (e.g., `http://localhost:8000/gmail/auth/callback`).
5. **Download** the credentials JSON and save it as `google_credentials.json` in the project root.

The JSON file should have this structure (generated by Google Cloud Console):
```json
{
  "web": {
    "client_id": "your-client-id.apps.googleusercontent.com",
    "client_secret": "your-client-secret",
    "redirect_uris": ["http://localhost:8000/gmail/auth/callback"],
    "auth_uri": "https://accounts.google.com/o/oauth2/auth",
    "token_uri": "https://oauth2.googleapis.com/token"
  }
}
```

**OAuth Scopes requested:**
- `gmail.send` â€” Send emails
- `gmail.readonly` â€” Read emails
- `gmail.compose` â€” Draft and compose emails

Once the server is running, authenticate by visiting `/gmail/auth/login`. The user's credentials are stored in MongoDB and refreshed automatically.

### Pocket TTS Setup

ARCIS uses [**Pocket TTS**](https://github.com/kyutai-labs/pocket-tts) for real-time text-to-speech with voice cloning.

- TTS model is loaded **on server startup** (runs in a thread executor to avoid blocking).
- The default voice is set via `TTS_DEFAULT_VOICE` (e.g., `alba`, a built-in preset).
- **Custom voices** can be uploaded at runtime via the `/chat/voice-upload` endpoint (accepts `.wav` files).
- Audio is streamed sentence-by-sentence as **Base64-encoded WAV** over Server-Sent Events (SSE).

> NOTE: TTS initialization can take a few seconds on first startup as the model loads into memory. If TTS fails to initialize, the server will still start â€” TTS endpoints will return error messages gracefully.

### Running the Server

```bash
# Run the server (default: port 8501)
python -m arcis

# Or with uvicorn directly
uvicorn arcis.__main__:api_server --host 0.0.0.0 --port 8501 --reload
```

The API documentation is available at:
- **Swagger UI**: `http://localhost:8501/docs`
- **ReDoc**: `http://localhost:8501/redoc`

---

## System Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ARCIS Backend                              â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ FastAPI   â”‚    â”‚              Core Engine                    â”‚   â”‚
â”‚  â”‚ Routers   â”‚â”€â”€> â”‚                                             â”‚   â”‚
â”‚  â”‚           â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚ â€¢ Chat    â”‚    â”‚  â”‚         LangGraph Workflows           â”‚  â”‚   â”‚
â”‚  â”‚ â€¢ Gmail   â”‚    â”‚  â”‚                                       â”‚  â”‚   â”‚
â”‚  â”‚ â€¢ Calendarâ”‚    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚   â”‚
â”‚  â”‚ â€¢ AutoFlowâ”‚    â”‚  â”‚  â”‚            Inputs              â”‚   â”‚  â”‚   â”‚
â”‚  â”‚ â€¢ Settingsâ”‚    â”‚  â”‚  â”‚                                â”‚   â”‚  â”‚   â”‚
â”‚  â”‚ â€¢ Onboard â”‚    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚                  â”‚                    â”‚  â”‚   â”‚
â”‚                   â”‚  â”‚                  â–¼                    â”‚  â”‚   â”‚
â”‚                   â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚   â”‚
â”‚                   â”‚  â”‚  â”‚      Agent Pipeline           â”‚    â”‚  â”‚   â”‚
â”‚                   â”‚  â”‚  â”‚ Planner â†’ Supervisor â†’ Agents â”‚    â”‚  â”‚   â”‚
â”‚                   â”‚  â”‚  â”‚           â†’ Replanner         â”‚    â”‚  â”‚   â”‚
â”‚                   â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚   â”‚
â”‚                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚                   â”‚                                             â”‚   â”‚
â”‚                   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚                   â”‚  â”‚  TTS   â”‚  â”‚  Gmail/ â”‚  â”‚ LLM Factory  â”‚  â”‚   â”‚
â”‚                   â”‚  â”‚Manager â”‚  â”‚ Calendarâ”‚  â”‚(5+ providers)â”‚  â”‚   â”‚
â”‚                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ MongoDB            â”‚  â”‚ Qdrant             â”‚                     â”‚
â”‚  â”‚ â€¢ User data        â”‚  â”‚ â€¢ Long-term memory â”‚                     â”‚
â”‚  â”‚ â€¢ Chat history     â”‚  â”‚ â€¢ Semantic search  â”‚                     â”‚
â”‚  â”‚ â€¢ Checkpoints      â”‚  â”‚ â€¢ User profile     â”‚                     â”‚
â”‚  â”‚ â€¢ Settings         â”‚  â”‚                    â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Project Structure

```
arcis-backend/
â”œâ”€â”€ config.py                    # Environment variable loading & Config class
â”œâ”€â”€ google_credentials.json      # Google OAuth client credentials
â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚
â””â”€â”€ arcis/                       # Main application package
    â”œâ”€â”€ __init__.py               # Exports Config
    â”œâ”€â”€ __main__.py               # FastAPI app, lifespan, middleware, router registration
    â”‚
    â”œâ”€â”€ core/                     # Business logic
    â”‚   â”œâ”€â”€ external_api/         # Third-party API wrappers
    â”‚   â”‚   â”œâ”€â”€ google.py         # Base Google API (OAuth credential loading)
    â”‚   â”‚   â”œâ”€â”€ gmail.py          # Gmail API wrapper (read/send/draft)
    â”‚   â”‚   â””â”€â”€ calendar.py       # Google Calendar wrapper
    â”‚   â”‚
    â”‚   â”œâ”€â”€ llm/                  # LLM infrastructure
    â”‚   â”‚   â”œâ”€â”€ factory.py        # LLMFactory â€” multi-provider client creation
    â”‚   â”‚   â”œâ”€â”€ providers.py      # LLMProvider enum (Gemini, Groq, etc.)
    â”‚   â”‚   â”œâ”€â”€ config_manager.py # Dynamic per-agent model configuration
    â”‚   â”‚   â”œâ”€â”€ llm_list.py       # Available models per provider
    â”‚   â”‚   â”œâ”€â”€ prompts.py        # System prompts for all agents
    â”‚   â”‚   â”œâ”€â”€ long_memory.py    # Qdrant-backed semantic memory (singleton)
    â”‚   â”‚   â”œâ”€â”€ short_memory.py   # MongoDB checkpointer for LangGraph
    â”‚   â”‚   â”œâ”€â”€ chat_history.py   # Decoupled chat history storage
    â”‚   â”‚   â”œâ”€â”€ memory_extractor.py # LLM-based fact extraction from conversations
    â”‚   â”‚   â””â”€â”€ pending_interrupt.py # Pending HITL interrupt storage
    â”‚   â”‚
    â”‚   â”œâ”€â”€ onboarding/           # User onboarding system
    â”‚   â”‚   â””â”€â”€ interviewer.py    # Multi-turn LLM interview â†’ Qdrant storage
    â”‚   â”‚
    â”‚   â”œâ”€â”€ tts/                  # Text-to-Speech
    â”‚   â”‚   â””â”€â”€ tts_manager.py    # Pocket TTS model management & streaming
    â”‚   â”‚
    â”‚   â”œâ”€â”€ utils/                # Utility modules
    â”‚   â”‚   â”œâ”€â”€ token_tracker.py  # Per-agent token usage tracking
    â”‚   â”‚   â””â”€â”€ emotion_tracker.py # User emotion analysis
    â”‚   â”‚
    â”‚   â”œâ”€â”€ workflow_manual/      # Manual (chat) workflow
    â”‚   â”‚   â”œâ”€â”€ manual_flow.py    # LangGraph graph definition & runner
    â”‚   â”‚   â”œâ”€â”€ agents/           # Agent node implementations
    â”‚   â”‚   â”‚   â”œâ”€â”€ planner.py    # Decomposes requests into step-by-step plans
    â”‚   â”‚   â”‚   â”œâ”€â”€ supervisor.py # Routes steps to the correct agent
    â”‚   â”‚   â”‚   â”œâ”€â”€ email_agent.py    # Handles email-related tasks
    â”‚   â”‚   â”‚   â”œâ”€â”€ booking_agent.py  # Handles booking/travel tasks
    â”‚   â”‚   â”‚   â”œâ”€â”€ utility_agent.py  # Handles general tasks (search, calendar, etc.)
    â”‚   â”‚   â”‚   â””â”€â”€ replanner.py      # Evaluates progress, re-plans if needed
    â”‚   â”‚   â””â”€â”€ tools/            # LangChain tools available to agents
    â”‚   â”‚       â”œâ”€â”€ email.py      # Send/draft email tool
    â”‚   â”‚       â”œâ”€â”€ calendar.py   # Calendar read/write tool
    â”‚   â”‚       â”œâ”€â”€ booking.py    # Booking/reservation tool
    â”‚   â”‚       â”œâ”€â”€ web_search.py # DuckDuckGo web search tool
    â”‚   â”‚       â””â”€â”€ memory_search.py # Long-term memory search tool
    â”‚   â”‚
    â”‚   â””â”€â”€ workflow_auto/        # Autonomous (email processing) workflow
    â”‚       â”œâ”€â”€ auto_flow.py      # Auto-flow graph, batch processor, interrupt resolver
    â”‚       â””â”€â”€ nodes/
    â”‚           â””â”€â”€ analyzer.py   # Email analysis node (replaces planner for auto)
    â”‚
    â”œâ”€â”€ database/
    â”‚   â””â”€â”€ mongo/
    â”‚       â””â”€â”€ connection.py     # Motor async MongoDB client & collection registry
    â”‚
    â”œâ”€â”€ models/                   # Pydantic & TypedDict models
    â”‚   â”œâ”€â”€ agents/
    â”‚   â”‚   â””â”€â”€ state.py          # AgentState & PlanStep (LangGraph state schema)
    â”‚   â”œâ”€â”€ llm.py                # LLMProvider enum
    â”‚   â””â”€â”€ errors.py             # Custom exceptions
    â”‚
    â”œâ”€â”€ router/                   # FastAPI route handlers
    â”‚   â”œâ”€â”€ routes.py             # Root/test routes
    â”‚   â”œâ”€â”€ chat.py               # Chat endpoints (text + TTS streaming)
    â”‚   â”œâ”€â”€ gmail.py              # Google OAuth login/callback/status/logout
    â”‚   â”œâ”€â”€ calendar.py           # Calendar events/todos/reminders
    â”‚   â”œâ”€â”€ auto_flow.py          # Pending interrupts management
    â”‚   â”œâ”€â”€ settings.py           # Agent LLM configuration CRUD
    â”‚   â”œâ”€â”€ onboarding.py         # Onboarding interview endpoints
    â”‚   â”œâ”€â”€ user_status.py        # User status tracking
    â”‚   â””â”€â”€ token_tracker.py      # Token usage reporting
    â”‚
    â””â”€â”€ utils/
        â””â”€â”€ text.py               # Text formatting utilities
```

### Core Components

#### LLM Factory (`core/llm/factory.py`)

The LLM Factory uses a **provider-agnostic pattern** to create LangChain chat model clients. Each agent can be configured to use a different provider and model.

**Supported Providers:**

| Provider | SDK | Models |
|----------|-----|--------|
| **Gemini** | `langchain-google-genai` | gemini-1.5-flash, gemini-2.0-flash, etc. |
| **Groq** | `langchain-openai` (compatible) | llama-3.1-8b-instant, qwen3-32b, etc. |
| **Cerebras** | `langchain-openai` (compatible) | llama3.1-8b |
| **Mistral AI** | `langchain-mistralai` | ministral-8b, mistral-small, etc. |
| **OpenRouter** | `langchain-openai` (compatible) | 100+ models via unified API |

#### Config Manager (`core/llm/config_manager.py`)

A **singleton** that manages per-agent LLM configurations. Configs are loaded from MongoDB on startup and fall back to built-in defaults. Agents can be reconfigured at runtime through the `/settings/agents` API without restarting the server.

#### TTS Manager (`core/tts/tts_manager.py`)

Manages the Pocket TTS model lifecycle:
- Loads the TTS model on startup in a background thread
- Maintains a registry of voice states (default + user-uploaded)
- Streams audio sentence-by-sentence as Base64-encoded WAV via SSE
- Custom voice cloning from uploaded `.wav` reference files

### Agent System

The agent pipeline is the heart of ARCIS. Each agent is a **LangGraph node** that receives the shared `AgentState` and performs its specialized role.

| Agent | Role | Tools |
|-------|------|-------|
| **Planner** | Decomposes user requests into a step-by-step plan with agent assignments | â€” |
| **Supervisor** | Routes the current pending step to the correct specialist agent | â€” |
| **EmailAgent** | Drafts, sends, and manages emails | `send_email`, `draft_email` |
| **BookingAgent** | Handles travel, reservations, and booking searches | `search_bookings`, `book_reservation` |
| **UtilityAgent** | General-purpose tasks: web search, calendar ops, memory queries | `web_search`, `calendar_tool`, `memory_search` |
| **Replanner** | Evaluates execution results and decides whether to continue, retry, or finish | â€” |
| **Analyzer** | *(Auto flow only)* Analyzes incoming emails and generates action plans | â€” |

#### Agent State

```python
class AgentState(TypedDict):
    thread_id: Optional[str]       # Conversation thread identifier
    input: str                     # Original user request
    plan: List[PlanStep]           # Decomposed task plan
    messages: Annotated[list, add_messages]  # Auto-accumulated conversation history
    context: Dict[str, Any]        # Accumulated context between agents
    last_tool_output: str          # Output from the last tool execution
    final_response: str            # Final user-facing response
    current_step_index: int        # Current step being executed
    next_node: Optional[str]       # Next agent to route to
    workflow_status: Optional[str] # CONTINUE | FINISHED | FAILED
```

### Memory System

ARCIS uses a **dual memory architecture**:

#### Short-Term Memory (MongoDB)
- **LangGraph Checkpointer** â€” Stores graph state between turns, enabling multi-turn conversations and workflow resumption.
- **Chat History** â€” Decoupled message log for frontend display (separate from LangGraph's internal state).

#### Long-Term Memory (Qdrant)
- **Semantic Vector Store** â€” Stores facts, preferences, and learned information as embeddings.
- **Categories**: `user_profile`, `preference`, `key_detail`, `learned_fact`
- **Embedding Modes**:
  - `offline` â€” FastEmbed (`BAAI/bge-small-en-v1.5`, 384-dim) â€” runs on CPU, no API calls
  - `online` â€” Gemini Embedding API (768-dim) â€” higher quality, requires API key
- **Memory Extraction** â€” After each conversation, an LLM analyzes the dialogue and extracts key facts, deduplicating against existing memories (cosine similarity threshold: 0.85).

### LLM Provider System

The system uses a **factory + config manager** pattern:

```
User Request
    â†“
Config Manager (get agent config from MongoDB / defaults)
    â†“
LLM Factory (create client for the configured provider)
    â†“
LangChain Chat Model (Gemini / Groq / Cerebras / Mistral / OpenRouter)
```

Default agent configurations can be viewed and updated via the `/settings` API, persisted to MongoDB.

---

## Workflows

### Manual Workflow (Chat)

The manual workflow is triggered when a user sends a message through the `/chat` endpoint.

**Flow:**
1. **Planner** receives the user message and conversation history. For simple queries (greetings, questions), it responds directly and ends. For complex tasks, it generates a structured plan with steps assigned to specific agents.
2. **Supervisor** examines the plan, finds the next pending step, and routes to the assigned agent.
3. **Specialist Agent** (Email/Booking/Utility) executes the step using its tools, updates the context with results.
4. **Replanner** evaluates the outcome. If the step succeeded, it marks it complete and checks for remaining steps. If it failed, it can generate corrective steps. Routes back to Supervisor if more work remains, or ends the workflow.
5. After completion, the **Memory Extractor** analyzes the conversation and stores key facts in long-term memory.

**Conversation Persistence:** Each conversation has a `thread_id`. The LangGraph checkpointer (MongoDB) preserves the full graph state, enabling:
- Multi-turn conversations within the same thread
- Resuming interrupted workflows
- Maintaining context across messages

### Autonomous Workflow (Email Processing)

The autonomous flow runs as a background task, processing unread emails without user interaction.

**Flow:**
1. Fetches the latest unread emails from Gmail.
2. **Analyzer** (replaces Planner) examines each email and decides if action is needed. Newsletters, spam, and FYI emails are ignored.
3. Actionable emails are routed through the same **Supervisor â†’ Agent â†’ Replanner** pipeline as the manual flow.
4. If an agent needs user confirmation (e.g., sending a reply, making a booking), it triggers an **interrupt** â€” the workflow pauses and a pending item is saved to MongoDB.
5. Users can review pending items via the `/auto_flow/pending` API and either **resolve** (provide an answer) or **dismiss** them.

### Human-in-the-Loop (HITL)

Agents can pause workflow execution when they need user input by using LangGraph's `interrupt()` mechanism:

- In the **Manual Flow**: The API returns an `interrupt` response type. The frontend displays the question and the user's reply resumes the graph.
- In the **Autonomous Flow**: Interrupts are saved as **pending items** in MongoDB. Users review them through the pending items API.

---

## API Reference

### Chat

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/chat` | Send a message to the manual workflow. Returns JSON with the AI response. |
| `POST` | `/chat/stream` | Send a message and receive TTS audio streamed via SSE. |
| `POST` | `/chat/voice-upload` | Upload a `.wav` file as a custom voice for TTS. |
| `GET` | `/chat/all_chats` | List all conversation threads (for sidebar). |
| `GET` | `/chat/{thread_id}` | Get full message history for a thread. |

**Chat Request Body:**
```json
{
  "message": "Send an email to John about the meeting",
  "thread_id": "optional-uuid-for-existing-thread"
}
```

### Gmail Authentication

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/gmail/auth/login` | Get Google OAuth login URL. |
| `GET` | `/gmail/auth/callback` | OAuth callback â€” exchanges code for credentials. |
| `GET` | `/gmail/auth/status` | Check if user is authenticated. |
| `GET` | `/gmail/auth/logout` | Remove stored Gmail credentials. |

### Calendar

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/calendar/events` | Fetch calendar events in a time range. |
| `GET` | `/calendar/todos` | Fetch todos in a time range. |
| `GET` | `/calendar/reminders` | Fetch reminders in a time range. |

Query parameters: `start_time` and `end_time` (ISO 8601 format).

### Autonomous Flow

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/auto_flow/pending` | List all pending interrupt items. |
| `POST` | `/auto_flow/resolve` | Resolve a pending item with user answer. |
| `POST` | `/auto_flow/dismiss` | Dismiss a pending item. |

### Onboarding

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/onboarding/start` | Start a new onboarding interview session. |
| `POST` | `/onboarding/respond` | Send answer, receive next question. |
| `GET` | `/onboarding/status` | Check if user has completed onboarding. |

### Settings

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/settings/models` | Get available LLM models grouped by provider. |
| `GET` | `/settings/agents` | Get current LLM config for all agents. |
| `PUT` | `/settings/agents` | Update LLM config for agents (provider, model, temperature). |

---

<p align="center">
  Built with â¤ï¸ using FastAPI, LangGraph, and a whole lot of LLMs.
</p>